{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov chain Monte Carlo: Amortized Approximate Likelihood Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypothesis\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.simulation import Simulator\n",
    "\n",
    "class NormalSimulator(Simulator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NormalSimulator, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return torch.randn(inputs.size(0), 1) + inputs\n",
    "\n",
    "simulator = NormalSimulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "prior = Uniform(-30, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio estimator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.nn import ConditionalMLPRatioEstimator as MLPRatioEstimator\n",
    "\n",
    "activation = torch.nn.ELU\n",
    "layers = [64, 64, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ratio estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.util.data import SimulatorDataset\n",
    "from hypothesis.nn.conditional_ratio_estimator import ConditionalRatioEstimatorCriterion\n",
    "\n",
    "inputs_shape = (1,)\n",
    "outputs_shape = (1,)\n",
    "ratio_estimator = MLPRatioEstimator(inputs_shape, outputs_shape, layers=layers, activation=activation)\n",
    "ratio_estimator.train()\n",
    "dataset = SimulatorDataset(simulator, prior)\n",
    "batch_size = 128\n",
    "criterion = ConditionalRatioEstimatorCriterion(ratio_estimator, batch_size)\n",
    "optimizer = torch.optim.Adam(ratio_estimator.parameters())\n",
    "epochs = 25\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, num_workers=2, batch_size=batch_size, drop_last=True)\n",
    "    num_batches = len(data_loader)\n",
    "    data_loader = iter(data_loader)\n",
    "    for batch_index in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, outputs = next(data_loader)\n",
    "        loss = criterion(inputs, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.cpu().item())\n",
    "    \n",
    "losses = np.array(losses)\n",
    "plt.plot(np.arange(epochs), np.log(losses), lw=2, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases the criterion based on the logits might be more numerically preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.nn.conditional_ratio_estimator import ConditionalRatioEstimatorLogitsCriterion\n",
    "\n",
    "ratio_estimator = MLPRatioEstimator(inputs_shape, outputs_shape, layers=layers, activation=activation)\n",
    "ratio_estimator.train()\n",
    "criterion = ConditionalRatioEstimatorLogitsCriterion(ratio_estimator, batch_size)\n",
    "optimizer = torch.optim.Adam(ratio_estimator.parameters())\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, num_workers=2, batch_size=batch_size, drop_last=True)\n",
    "    num_batches = len(data_loader)\n",
    "    data_loader = iter(data_loader)\n",
    "    for batch_index in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, outputs = next(data_loader)\n",
    "        loss = criterion(inputs, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.cpu().item())\n",
    "    \n",
    "losses = np.array(losses)\n",
    "plt.plot(np.arange(epochs), np.log(losses), lw=2, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the ratio estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior inference using MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
